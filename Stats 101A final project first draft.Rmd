---
title: 'Stats 101A Project: Group Project First Draft'
author: "Simran Vatsa, Naren Akurati, Sohom Paul, Ashwin Ayyasamy, Jeremy Phan"
date: "3/16/2018"
output:
  pdf_document: default
  html_document: default
---

##Data Cleanup
Consulted codebook to decide which codes could be converted to NAs. Changed "not answered" to NA, as that is information we do not have. Also converted variables coded to denote "_ or more" to NAs, as that is information we do not have and cannot create. We did not convert 8 (8 or more) in Household or Children, and we converted 0 (Inapplicable) and 8 (Don't know) to 2 (No) in Instagram.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo=FALSE}
library(alr3)
#data cleanup
happiness_data <- read.table("Happiness.txt", header = TRUE)
happiness_data$Household[happiness_data$Household == 9] <- NA
happiness_data$Health[happiness_data$Health == 8 | happiness_data$Health == 9 |  happiness_data$Health == 0] <- NA
happiness_data$Health[happiness_data$Health == 1] <- 400
happiness_data$Health[happiness_data$Health == 2] <- 300
happiness_data$Health[happiness_data$Health == 3] <- 2
happiness_data$Health[happiness_data$Health == 4] <- 1
happiness_data$Health[happiness_data$Health == 400] <- 4
happiness_data$Health[happiness_data$Health == 300] <- 3
happiness_data$OwnHome[happiness_data$OwnHome == 0 | happiness_data$OwnHome == 8 | happiness_data$OwnHome == 9] <- NA
#Instagram - Set 'don't know' and 'inapplicable' to 'No'
happiness_data$Instagram[happiness_data$Instagram == 0 | happiness_data$Instagram == 8] <- 2
happiness_data$Instagram[happiness_data$Instagram == 9] <- NA
happiness_data$Marital[happiness_data$Marital == 9] <- NA
happiness_data$Age[happiness_data$Age == 89 | happiness_data$Age == 98 | happiness_data$Age == 99] <- NA
happiness_data$Children[happiness_data$Children == 9] <- NA
happiness_data$Education[happiness_data$Education == 97 | happiness_data$Education == 98 | happiness_data$Education == 99] <- NA
happiness_data$JobSat[happiness_data$JobSat == 0 | happiness_data$JobSat == 8 | happiness_data$JobSat == 9] <- NA
happiness_data$Income[happiness_data$Income == 0 | happiness_data$Income == 999998 | happiness_data$Income == 999999] <- NA
happiness_data$WorkHrs[happiness_data$WorkHrs == -1 | happiness_data$WorkHrs == 998 | happiness_data$WorkHrs == 999] <- NA
happiness_data$Happy[happiness_data$Happy == 0 | happiness_data$Happy == 8 | happiness_data$Happy == 9] <- NA
happiness_data$Happy[happiness_data$Happy == 1] <- 100
happiness_data$Happy[happiness_data$Happy == 3] <- 1
happiness_data$Happy[happiness_data$Happy == 100] <- 3
```

##First Model
We start with the full model with everything except *Health* and *WorkHrs* predictors. *Health* and *WorkHrs* predictors throw errors due to large number of NAs (811 and 1898 NAs respectively) and few categories. $R^2$ currently at 0.2811438 and $R^2_{adj}$ at 0.2069141.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
attach(happiness_data)
#Factoring Categorical Variables
JobSat.f <- factor(JobSat); OwnHome.f <- factor(OwnHome); Marital.f <- factor(Marital); Instagram.f <- factor(Instagram); Health.f <- factor(Health); Household.f <- factor(Household); Children.f <- factor(Children); Sex.f <- factor(Sex)

#Couldn't include Health as it throws an error
full_model <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education + JobSat.f + Income + Age + Sex.f)

sum(is.na(Health))
sum(is.na(WorkHrs))

summary(full_model)$r.squared
summary(full_model)$adj.r.squared
```

##Transformation
Transformation of numerical variables *Education*, *Income*, and *Age* using powertransform. Understanding of the effects of wealth lead us to use log transformation of *Income* predictor which proved more effective than the estimated transformation parameter. Inverse rseponse plot suggested lambda close to 0. As such, we took log(*Happy*) for a simpler model. $R^2$ currently at 0.3518696 and $R^2_{adj}$ at 0.2438479.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Power transformation
powerTransform(cbind(Household.f, OwnHome.f, Instagram.f, Marital.f, Children.f, Education, JobSat.f, Income, Age, Sex.f)~1)

Education_transformed <- Education^0.7943619
Income_transformed <- Income^0.2140292
Income_log <- log(Income)
Age_transformed <- Age^0.3192108

full_model_transform_log <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log  + Age_transformed + Sex.f)

summary(full_model_transform_log)$r.squared
summary(full_model_transform_log)$adj.r.squared

#Inverse response plot
par(mfrow=c(2,2))
inverseResponsePlot(full_model_transform_log, key = TRUE)
full_model_transform_log_inverse_response <- lm(log(Happy) ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log  + Age_transformed + Sex.f)
summary(full_model_transform_log_inverse_response)$r.squared
summary(full_model_transform_log_inverse_response)$adj.r.squared
```

##Cursory Variable Selection
We look at number of NAs in our predictors. *OwnHome*, *JobSat*, and *Income* all have a high number of NAs (812, 1612, and 1039 respectively). From summary, predictors showing p-values over 0.05 are *OwnHome*, *Instagram*, *Marital*, *Children*, *Education*, and *Age*. These may need to be removed.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo = FALSE}
df_NA_count <- data.frame(c(sum(is.na(Household.f)), sum(is.na(OwnHome.f)), sum(is.na(Instagram.f)), sum(is.na(Marital.f)), sum(is.na(Children.f)), sum(is.na(Education_transformed)), sum(is.na(JobSat.f)), sum(is.na(Income_log)), sum(is.na(Age_transformed)), sum(is.na(Sex.f))))
df_NA_count
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo = FALSE}
summary(full_model_transform_log_inverse_response)
```

##Partial F-tests
We start with manual F-tests based on backward selection (removing the least significant variables first each iteration). Removing all variables reduces the accuracy of our model far too much. We remove the most insignifcant predictor *Instagram*. We remove another insignificant predictor *OwnHome*, as it also introduces many NAs.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo = FALSE}
drop1(full_model_transform_log_inverse_response, test = "F")
drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f), test = "F")
drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f), test = "F")
drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f), test = "F")
drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f -Sex.f), test = "F")
drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f -Sex.f -Age_transformed), test = "F")
drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f -Sex.f -Age_transformed -Education_transformed), test = "F")
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo = FALSE}

```

##AIC
```{r}
library(leaps)
#X <- cbind(Household.f, OwnHome.f, Instagram.f, Marital.f, Children.f, Education_transformed, JobSat.f, Income_log, Age_transformed, Sex.f)
#b <- regsubsets(as.matrix(X), log(Happy))
#rs <- summary(b)
#rs$adjr2
Rad <- summary(full_model_transform_log_inverse_response)$adj.r.squared
om1 <- lm(Happy ~ Household.f)
om2 <- lm(Happy ~ Household.f + OwnHome.f)
om3 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f)
om4 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f)
om5 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f)
om6 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed)
om7 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f)
om8 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log)
om9 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log + Age_transformed)
om10 <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log + Age_transformed + Sex.f)
n = length(om1$residuals) 

p <- 1
AIC1 <- extractAIC(om1,k=2)[2] # AIC
AICc1 <- extractAIC(om1,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC1 <- extractAIC(om1,k=log(n))[2] # BIC
p <- 2
AIC2 <- extractAIC(om2,k=2)[2] # AIC
AICc2 <- extractAIC(om2,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC2 <- extractAIC(om2,k=log(n))[2] # BIC
p <- 3
AIC3 <- extractAIC(om3,k=2)[2] # AIC
AICc3 <- extractAIC(om3,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC3 <- extractAIC(om3,k=log(n))[2] # BIC
p <- 4
AIC4 <- extractAIC(om4,k=2)[2] # AIC
AICc4 <- extractAIC(om4,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC4 <- extractAIC(om4,k=log(n))[2] # BIC
p <- 5
AIC5 <- extractAIC(om5,k=2)[2] # AIC
AICc5 <- extractAIC(om5,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC5 <- extractAIC(om5,k=log(n))[2] # BIC
p <- 6
AIC6 <- extractAIC(om6,k=2)[2] # AIC
AICc6 <- extractAIC(om6,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC6 <- extractAIC(om6,k=log(n))[2] # BIC
p <- 7
AIC7 <- extractAIC(om7,k=2)[2] # AIC
AICc7 <- extractAIC(om7,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC7 <- extractAIC(om7,k=log(n))[2] # BIC
p <- 8
AIC8 <- extractAIC(om8,k=2)[2] # AIC
AICc8 <- extractAIC(om8,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC8 <- extractAIC(om8,k=log(n))[2] # BIC
p <- 9
AIC9 <- extractAIC(om9,k=2)[2] # AIC
AICc9 <- extractAIC(om9,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC9 <- extractAIC(om9,k=log(n))[2] # BIC
p <- 10
AIC10 <- extractAIC(om10,k=2)[2] # AIC
AICc10 <- extractAIC(om10,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC10 <- extractAIC(om10,k=log(n))[2] # BIC

AIC <- c(AIC1,AIC2,AIC3, AIC4, AIC5, AIC6, AIC7, AIC8, AIC9, AIC10)
AICc <- c(AICc1, AICc2, AICc3, AICc4, AICc5, AICc6, AICc7, AICc8, AICc9, AICc10)
BIC <- c(BIC1, BIC2, BIC3, BIC4, BIC5, BIC6, BIC7, BIC8, BIC9, BIC10)

opmodel <- data.frame(Size=1:10, AIC=AIC, AICc=AICc, BIC=BIC)
opmodel

duplicate <- full_model_transform_log_inverse_response
duplicate_data <- happiness_data

mint <- lm(log(Happy)~1)
forwardAIC <- step(mint, scope=list(lower=~1, upper= ~Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log + Age_transformed + Sex.f, direction="forward"))
```

##Leverages, Outliers, and Influential Points
Now we see how many bad leverage points we have. We have 4 bad leverage points. We conclude that our final model is accurate.
```{r}
StanRes1 <- rstandard(full_model_transform_log_inverse_response); leverage1 <- hatvalues(full_model_transform_log_inverse_response); cookd1 <- cooks.distance(full_model_transform_log_inverse_response); p <- 10; n <- 176

a <- which(StanRes1 > 2 | StanRes1 < -2); b <- which(leverage1 > 2*(p+1)/n)
intersect(a, b)
```


##OLD STUFF
The first conclusion we came to in our model selection process was that WorkHrs had to be excluded, as there were 1898 missing values, most of which were -1 (Inapplicable). Its sheer amount of missing values made it ineligible for model fitting - every attempt to include it resulted in an error being thrown. 
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Finding the number of NAs 
sum(is.na(happiness_data$WorkHrs))
#Insta = 10, Marital = 1; #Household = 1; #Health = 811; #OwnHome = 812; #JobSat = 1612; #WorkHrs = 1898; #Income = 1039
```

We plotted the full model (without WorkHrs). This factored in around 190 observations, as all the rest had NAs under some variables. We found the Residuals vs Fitted plot showed a linear trend, a result of some of the predictor variables being categorical. The standardized residual plot also showed a pattern that skewed the plot much more than it did in the Residuals vs. Fitted plot. 
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
attach(happiness_data)
#Factoring Categorical Variables
JobSat.f <- factor(JobSat); OwnHome.f <- factor(OwnHome); Marital.f <- factor(Marital); Instagram.f <- factor(Instagram); Health.f <- factor(Health)
#Couldn't include Health as it throws an error
full_model <- lm(Happy ~ Household + OwnHome.f + Instagram.f + Marital.f + Children + Education + JobSat.f + Income + Age + Sex)
```

We decided the best way to proceed would be to test each variable's significance individually. We created models with individual variables and Happy, finding that Instagram and Sex did not have statistically significant linear relationships to Happy.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
insta <- lm(Happy ~ Instagram)
#summary(insta); plot(insta); Instagram is insignificant
sex <- lm(Happy ~ Sex)
#summary(sex); plot(sex); Sex is insignificant
```

We then used partial F-tests to verify these findings, as well as potentially weed out other variables. To do so, we created models that each excluded one variable and then tested them against our full model. This method found Children and Education to be insignificant in addition to Instagram and Sex. OwnHome, JobSat, Income and Age threw errors in partial F-testing, so we have not included the code for those.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
noMarital <- lm(Happy ~ Sex + JobSat.f + OwnHome.f + Household + Education + Age + Income + Children + Instagram.f); anova(full_model, noMarital)$`Pr(>F)` 
#Marital is significant
noHousehold <- lm(Happy ~ Sex + JobSat.f + OwnHome.f + Marital.f + Education + Age + Income + Children + Instagram.f); anova(full_model, noHousehold)$`Pr(>F)`
#Household is significant
noSex <- lm(Happy ~ JobSat.f + OwnHome.f + Household + Marital.f + Education + Age + Income + Children + Instagram.f); anova(full_model, noSex)$`Pr(>F)`
#Sex is insignificant
noInstagram <- lm(Happy ~ Sex + JobSat.f + OwnHome.f + Household + Marital.f + Education + Age + Income + Children); anova(full_model, noInstagram)$`Pr(>F)`
#Instagram is insignificant
noChildren <- lm(Happy ~ Sex + JobSat.f + OwnHome.f + Household + Marital.f + Education + Age + Income + Instagram.f); anova(full_model, noChildren)$`Pr(>F)`
#Children is insignificant
noEducation <- lm(Happy ~ Sex + JobSat.f + OwnHome.f + Household + Marital.f + Age + Income + Children + Instagram.f); anova(full_model, noEducation)$`Pr(>F)`
#Education is insignificant
```

After eliminating the four insignificant variables, we obtained AIC, AICc and BIC values, which were lowest when all six variables were included. Performing forward selection showed OwnHome to be insignificant and performing backward selection showed Age to be insignificant. Since the forward and backward selections were not in agreement, this did not seem like strong enough evidence to exclude the variables to us. We found including all 6 variables gave us the lowest values for each, so we did not choose to omit any variables from the model in this process. 
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Eliminating education, instagram, children, sex
new_model <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household + Income + Age)

Rad <- summary(new_model)$adj.r.squared
om1 <- lm(Happy ~ JobSat.f)
om2 <- lm(Happy ~ JobSat.f + OwnHome.f)
om3 <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f)
om4 <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household)
om5 <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household + Age)
om6 <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household + Age + Income)
n = length(Happy)

p <- 1
oms1 <- summary(om1)
AIC1 <- extractAIC(om1,k=2)[2] # AIC
AICc1 <- extractAIC(om1,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC1 <- extractAIC(om1,k=log(n))[2] # BIC
p <- 2
oms2 <- summary(om2)
AIC2 <- extractAIC(om2,k=2)[2] # AIC
AICc2 <- extractAIC(om2,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC2 <- extractAIC(om2,k=log(n))[2] # BIC
p <- 3
oms3 <- summary(om3)
AIC3 <- extractAIC(om3,k=2)[2] # AIC
AICc3 <- extractAIC(om3,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC3 <- extractAIC(om3,k=log(n))[2] # BIC
p <- 4
oms4 <- summary(om4)
AIC4 <- extractAIC(om4,k=2)[2] # AIC
AICc4 <- extractAIC(om4,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC4 <- extractAIC(om4,k=log(n))[2] # BIC
p <- 5
oms5 <- summary(om5)
AIC5 <- extractAIC(om5,k=2)[2] # AIC
AICc5 <- extractAIC(om5,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC5 <- extractAIC(om5,k=log(n))[2] # BIC
p <- 6
oms6 <- summary(om6)
AIC6 <- extractAIC(om6,k=2)[2] # AIC
AICc6 <- extractAIC(om6,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC6 <- extractAIC(om6,k=log(n))[2] # BIC

AIC <- c(AIC1,AIC2,AIC3, AIC4, AIC5, AIC6)
AICc <- c(AICc1, AICc2, AICc3, AICc4, AICc5, AICc6)
BIC <- c(BIC1, BIC2, BIC3, BIC4, BIC5, BIC6)

opmodel <- data.frame(Size=1:6, Radj2= Rad, AIC=AIC, AICc=AICc, BIC=BIC)
opmodel
#Lowest AIC, AICc, BIC values occur when size = 6. Thus, we are retaining all variables

#Checking Forward Selection 
add1(lm(Happy~1), Happy~ JobSat.f + OwnHome.f + Marital.f + Household + Age + Income, test="F")$`Pr(>F)` #prints p-value
#Age seems to be insignificant

#Performing another forward selection to see if age is actually insignificant
add1(lm(Happy ~ JobSat.f), Happy~ JobSat.f + OwnHome.f + Marital.f + Household + Age + Income, test="F")$`Pr(>F)` #prints p-value
#Backward Selection to see check the significance of variables
drop1(lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household + Age + Income), test="F")$`Pr(>F)` #prints p-value
#Ownhome seems to be insignificant
drop1(lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household  + Income), test="F")$`Pr(>F)` #prints p-value
```

Our untransformed model thus contained JobSat, OwnHome, Marital and Household in factor form, as well as the numerical variables Income and Age. Its R squared value was 0.2844, and its adjusted R squared value improved to 0.2105. 
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
Household.f <- factor(Household)

Final_model <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household.f + Income + Age)
summary(Final_model)$r.squared
summary(Final_model)$adj.r.squared
```

We used both the Box Cox and inverse response plot methods in transforming our model. Per Box Cox, we raised Age to the power of 0.226. Intuitively, looking at the relationship between Income and Happy, we decided on a logarithmic transformation on Income, as well. The adjusted R squared value reduced a little from this transformation, to 0.2099, and R squared dropped to 0.2838. The inverse response plot suggested a lambda of -0.1130549, but the RSS for a lambda of 0 was very similar, so we took the log transformation of our response variable instead, as it it represented a better representation of real world data. We ended with an $R^2$ value of 0.3092 and an adjusted $R^2$ of 0.2378.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Box Cox transformation
powerTransform(cbind(JobSat.f, OwnHome.f, Marital.f, Household.f, Income, Age)~1)
Age_transformed <- Age^0.226
m_new <- lm(Happy ~ JobSat.f + OwnHome.f + Marital.f + Household.f + log(Income) + Age_transformed)
#summary(m_new)

#Inverse response plot
par(mfrow=c(2,2))
m_new <- lm(log(Happy) ~ JobSat.f + OwnHome.f + Marital.f + Household.f + log(Income) + Age_transformed)
summary(m_new)
```

Now we see how many bad leverage points we have. We have 7 bad leverage points. We conclude that our final model is accurate.
```{r}
StanRes1 <- rstandard(m_new); leverage1 <- hatvalues(m_new); cookd1 <- cooks.distance(m_new); p <- 7; n <- 186
a <- which(StanRes1 > 2 | StanRes1 < -2); b <- which(leverage1 > 2*(p+1)/n)
intersect(a, b)
```










