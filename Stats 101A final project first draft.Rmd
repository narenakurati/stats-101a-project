---
title: 'Stats 101A Project'
author: "Naren Akurati, Simran Vatsa, Ashwin Ayyasamy, Sohom Paul, Jeremy Phan"
date: "3/23/2018"
output:
  pdf_document: default
  html_document: default
---

##Data Cleanup
Consulted codebook to decide which codes could be converted to NAs. Changed "not answered" to NA, as that is information we do not have. Also converted variables coded to denote "_ or more" to NAs, as that is information we do not have and cannot create. We did not convert 8 (8 or more) in Household or Children, and we converted 0 (Inapplicable) and 8 (Don't know) to 2 (No) in Instagram.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo=FALSE}
library(alr3)
#data cleanup
happiness_data <- read.table("Happiness.txt", header = TRUE)
happiness_data$Household[happiness_data$Household == 9] <- NA
happiness_data$Health[happiness_data$Health == 8 | happiness_data$Health == 9 |  happiness_data$Health == 0] <- NA
happiness_data$Health[happiness_data$Health == 1] <- 400
happiness_data$Health[happiness_data$Health == 2] <- 300
happiness_data$Health[happiness_data$Health == 3] <- 2
happiness_data$Health[happiness_data$Health == 4] <- 1
happiness_data$Health[happiness_data$Health == 400] <- 4
happiness_data$Health[happiness_data$Health == 300] <- 3
happiness_data$OwnHome[happiness_data$OwnHome == 0 | happiness_data$OwnHome == 8 | happiness_data$OwnHome == 9] <- NA
#Instagram - Set 'don't know' and 'inapplicable' to 'No'
happiness_data$Instagram[happiness_data$Instagram == 0 | happiness_data$Instagram == 8] <- 2
happiness_data$Instagram[happiness_data$Instagram == 9] <- NA
happiness_data$Marital[happiness_data$Marital == 9] <- NA
happiness_data$Age[happiness_data$Age == 89 | happiness_data$Age == 98 | happiness_data$Age == 99] <- NA
happiness_data$Children[happiness_data$Children == 9] <- NA
happiness_data$Education[happiness_data$Education == 97 | happiness_data$Education == 98 | happiness_data$Education == 99] <- NA
happiness_data$JobSat[happiness_data$JobSat == 0 | happiness_data$JobSat == 8 | happiness_data$JobSat == 9] <- NA
happiness_data$Income[happiness_data$Income == 0 | happiness_data$Income == 999998 | happiness_data$Income == 999999] <- NA
happiness_data$WorkHrs[happiness_data$WorkHrs == -1 | happiness_data$WorkHrs == 998 | happiness_data$WorkHrs == 999] <- NA
happiness_data$Happy[happiness_data$Happy == 0 | happiness_data$Happy == 8 | happiness_data$Happy == 9] <- NA
happiness_data$Happy[happiness_data$Happy == 1] <- 100
happiness_data$Happy[happiness_data$Happy == 3] <- 1
happiness_data$Happy[happiness_data$Happy == 100] <- 3
```

##First Model
We start with the full model with everything except *Health* and *WorkHrs* predictors. *Health* and *WorkHrs* predictors throw errors due to large number of NAs (811 and 1898 NAs respectively) and few categories. $R^2$ currently at 0.2811438 and $R^2_{adj}$ at 0.2069141.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
attach(happiness_data)
JobSat.f <- factor(JobSat); OwnHome.f <- factor(OwnHome); Marital.f <- factor(Marital); Instagram.f <- factor(Instagram); Health.f <- factor(Health); Household.f <- factor(Household); Children.f <- factor(Children); Sex.f <- factor(Sex)

full_model <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education + JobSat.f + Income + Age + Sex.f)

sum(is.na(Health))
sum(is.na(WorkHrs))

summary(full_model)$r.squared
summary(full_model)$adj.r.squared
```

##Transformation
Transformation of numerical variables *Education*, *Income*, and *Age* using powertransform. Understanding of the effects of wealth lead us to use log transformation of *Income* predictor which proved more effective than the estimated transformation parameter. Inverse rseponse plot suggested lambda close to 0. As such, we took log(*Happy*) for a simpler model. $R^2$ currently at 0.3518696 and $R^2_{adj}$ at 0.2438479.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Power transformation
powerTransform(cbind(Household.f, OwnHome.f, Instagram.f, Marital.f, Children.f, Education, JobSat.f, Income, Age, Sex.f)~1)

Education_transformed <- Education^0.7943619
Income_transformed <- Income^0.2140292
Income_log <- log(Income)
Age_transformed <- Age^0.3192108

full_model_transform_log <- lm(Happy ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log  + Age_transformed + Sex.f)

summary(full_model_transform_log)$r.squared
summary(full_model_transform_log)$adj.r.squared

#Inverse response plot
par(mfrow=c(2,1))
inverseResponsePlot(full_model_transform_log, key = TRUE)

full_model_transform_log_inverse_response <- lm(log(Happy) ~ Household.f + OwnHome.f + Instagram.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log  + Age_transformed + Sex.f)

summary(full_model_transform_log_inverse_response)$r.squared
summary(full_model_transform_log_inverse_response)$adj.r.squared
```

##Cursory Variable Selection
We look at number of NAs in our predictors. *OwnHome*, *JobSat*, and *Income* all have a high number of NAs (812, 1612, and 1039 respectively). From summary, predictors showing p-values over 0.05 are *OwnHome*, *Instagram*, *Marital*, *Children*, *Education*, and *Age*. These may need to be removed.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
df_NA_count <- data.frame(c(sum(is.na(Household.f)), sum(is.na(OwnHome.f)), sum(is.na(Instagram.f)), sum(is.na(Marital.f)), sum(is.na(Children.f)), sum(is.na(Education_transformed)), sum(is.na(JobSat.f)), sum(is.na(Income_log)), sum(is.na(Age_transformed)), sum(is.na(Sex.f))))
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo = FALSE}
#summary(full_model_transform_log_inverse_response)
```

##Partial F-test - Further Variable Selection
We start with manual F-tests based on backward selection (removing the least significant variables first each iteration). We remove all insigificant variables (*Instagram*, *Children*, *OwnHome*, *Sex*, and *Age*). Our $R^2$ and $R^2_{adj}$ values dropped significantly to 0.1718834 and 0.1467889 respectively, but we do this in order to avoid overfitting the data.
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
full <- drop1(full_model_transform_log_inverse_response, test = "F")
reduced_1 <- drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f), test = "F")
reduced_2 <- drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f), test = "F")
reduced_3 <- drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f), test = "F")
reduced_4 <- drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f -Sex.f), test = "F")
reduced_5 <- drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f -Sex.f -Age_transformed), test = "F")
reduced_6 <- drop1(update(full_model_transform_log_inverse_response, ~ . -Instagram.f -Children.f -OwnHome.f -Sex.f -Age_transformed -Education_transformed), test = "F")
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
updated_model <- lm(log(Happy) ~ Household.f + Marital.f + Education_transformed + JobSat.f + Income_log)

summary(updated_model)$r.squared
summary(updated_model)$adj.r.squared
```

##Interaction Terms
We tested a new model with all the possible interaction terms. Based on the summary, we elminated all the insignificant interaction terms and finally arrived at a new model with $R^2$ value of 0.3555 and an $R^2_{adj}$ of 0.265.
```{r}
# #Adding interaction terms 
# full_interaction_terms <- lm(log(Happy) ~ Household.f + OwnHome.f + Marital.f + Children.f + Education_transformed + JobSat.f + Income_log  + Age_transformed + Sex.f)
#   
# lm(log(Happy) ~ JobSat.f + OwnHome.f + Marital.f + Household.f + log(Income) + Age_transformed + JobSat.f:Income + JobSat.f:Age_transformed + OwnHome.f:Age_transformed + OwnHome.f:Income + Household.f:Income + Household.f:Age_transformed + Marital.f:Income + Marital.f:Age_transformed)
# summary(m_new1)
# 
# #Deleting insignificant interaction terms
# final_model <- lm(log(Happy) ~ JobSat.f + OwnHome.f + Marital.f + Household.f + log(Income) + Age_transformed + Household.f:Income)
# summary(m_new2)
# plot(m_new2)
```

##AIC, AICc, BIC
AIC, AICc, and BIC subsets show a subset of size 3 to be optimal. However, doing so drops our $R^2$ and $R^2_{adj}$ significantly and cuts our number of predictors drastically. We choose not to implement the subset of size 3
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60), echo = FALSE}
om1 <- lm(Happy ~ Household.f)
om2 <- lm(Happy ~ Household.f + Marital.f)
om3 <- lm(Happy ~ Household.f + Marital.f + Education_transformed)
om4 <- lm(Happy ~ Household.f + Marital.f + Education_transformed + JobSat.f)
om5 <- lm(Happy ~ Household.f + Marital.f + Education_transformed + JobSat.f + Income_log)
n = length(om1$residuals)

p <- 1
AIC1 <- extractAIC(om1,k=2)[2] # AIC
AICc1 <- extractAIC(om1,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC1 <- extractAIC(om1,k=log(n))[2] # BIC
p <- 2
AIC2 <- extractAIC(om2,k=2)[2] # AIC
AICc2 <- extractAIC(om2,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC2 <- extractAIC(om2,k=log(n))[2] # BIC
p <- 3
AIC3 <- extractAIC(om3,k=2)[2] # AIC
AICc3 <- extractAIC(om3,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC3 <- extractAIC(om3,k=log(n))[2] # BIC
p <- 4
AIC4 <- extractAIC(om4,k=2)[2] # AIC
AICc4 <- extractAIC(om4,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC4 <- extractAIC(om4,k=log(n))[2] # BIC
p <- 5
AIC5 <- extractAIC(om5,k=2)[2] # AIC
AICc5 <- extractAIC(om5,k=2)[2]+2*(p+2)*(p+3)/(n-p-1) # AICc
BIC5 <- extractAIC(om5,k=log(n))[2] # BIC

AIC <- c(AIC1,AIC2,AIC3, AIC4, AIC5)
AICc <- c(AICc1, AICc2, AICc3, AICc4, AICc5)
BIC <- c(BIC1, BIC2, BIC3, BIC4, BIC5)

opmodel <- data.frame(Size=1:5, AIC=AIC, AICc=AICc, BIC=BIC)
opmodel
```


##Leverages, Outliers, and Influential Points
Now we see how many bad leverage points we have. We have 9 bad leverage points. Amongst 600 observations, this is reasonable. We conclude that our final model is accurate.
```{r}
StanRes1 <- rstandard(updated_model); leverage1 <- hatvalues(updated_model); cookd1 <- cooks.distance(updated_model); p <- 9; n <- 600

a <- which(StanRes1 > 2 | StanRes1 < - 2); b <- which(leverage1 > 2*(p+1)/n)
intersect(a, b)
```

##Final Model
```{r}
summary(updated_model)
```











